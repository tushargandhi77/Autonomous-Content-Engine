{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bf595800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import operator\n",
    "from pathlib import  Path\n",
    "from typing import TypedDict,List,Optional,Literal,Annotated\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.types import Send\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "from langchain_tavily import TavilySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "cfbbb104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f843a",
   "metadata": {},
   "source": [
    "## Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "09878507",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task(BaseModel):\n",
    "    id: int\n",
    "    title: str\n",
    "\n",
    "    goal: str = Field(\n",
    "        ...,\n",
    "        description=\"One sentence describing what the reader should be able to do/understand after this section.\"\n",
    "    )\n",
    "\n",
    "    bullets: List[str] = Field(\n",
    "        ...,\n",
    "        min_length=3,\n",
    "        max_length=6,\n",
    "        description=\"2-3 concrete, non-overlapping subpoints to cover in this section.\",\n",
    "    )\n",
    "\n",
    "    target_words : str = Field(...,description=\"Target word count for this section (30-50).\")\n",
    "\n",
    "\n",
    "    tags: List[str] = Field(default_factory=list)\n",
    "    requires_research: bool = False\n",
    "    requires_citations: bool = False\n",
    "    requires_code: bool = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e113f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plan(BaseModel):\n",
    "    blog_title : str\n",
    "    audience : str\n",
    "    tone: str\n",
    "\n",
    "    blog_kind: Literal[\"explainer\", \"tutorial\", \"news_roundup\", \"comparison\", \"system_design\"] = \"explainer\"\n",
    "    constraints: List[str] = Field(default_factory=list)\n",
    "    tasks: List[Task]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ba6f46a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouterDecision(BaseModel):\n",
    "    needs_research: bool\n",
    "    mode: Literal[\"closed_book\", \"hybrid\", \"open_book\"]\n",
    "    queries: List[str] = Field(default_factory=list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "04589f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvidenceItem(BaseModel):\n",
    "    title: str\n",
    "    url: str\n",
    "    published_at: Optional[str] = None  # keep if Tavily provides; DO NOT rely on it\n",
    "    snippet: Optional[str] = None\n",
    "    source: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "aff01ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvidencePack(BaseModel):\n",
    "    evidence: List[EvidenceItem] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a1af1299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSpec(BaseModel):\n",
    "    placeholder: str = Field(..., description=\"e.g. [[IMAGE_1]]\")\n",
    "    filename: str = Field(..., description=\"Save under images/, e.g. qkv_flow.png\")\n",
    "    alt: str\n",
    "    caption: str\n",
    "    prompt: str = Field(..., description=\"Prompt to send to the image model.\")\n",
    "    size: Literal[\"1024x1024\", \"1024x1536\", \"1536x1024\"] = \"1024x1024\"\n",
    "    quality: Literal[\"low\", \"medium\", \"high\"] = \"medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "783754c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalImagePlan(BaseModel):\n",
    "    md_with_placeholders: str\n",
    "    images: List[ImageSpec] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8366895b",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "febe6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "\n",
    "    topic: str\n",
    "\n",
    "    # routing / research\n",
    "    mode: str\n",
    "    needs_research: bool\n",
    "    queries: List[str]\n",
    "    evidence: List[EvidenceItem]\n",
    "    plan: Optional[Plan]\n",
    "\n",
    "    # workers\n",
    "    sections: Annotated[List[tuple[int, str]], operator.add]  # (task_id, section_md)\n",
    "\n",
    "    # reducer/image\n",
    "    merged_md: str\n",
    "    md_with_placeholders: str\n",
    "    image_specs: List[dict]\n",
    "\n",
    "    final: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b57fdbe",
   "metadata": {},
   "source": [
    "## Define LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "48dba2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c108be4d",
   "metadata": {},
   "source": [
    "## Router Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1dbefe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUTER_SYSTEM = \"\"\" \n",
    "You are a routing module for a technical blog planner.\n",
    "\n",
    "Decide whether web research is needed BEFORE planning.\n",
    "\n",
    "Modes:\n",
    "- closed_book (needs_research=false):\n",
    "  Evergreen topics where correctness does not depend on recent facts (concepts, fundamentals).\n",
    "- hybrid (needs_research=true):\n",
    "  Mostly evergreen but needs up-to-date examples/tools/models to be useful.\n",
    "- open_book (needs_research=true):\n",
    "  Mostly volatile: weekly roundups, \"this week\", \"latest\", rankings, pricing, policy/regulation.\n",
    "\n",
    "If needs_research=true:\n",
    "- Output 2-3 high-signal queries.\n",
    "- Queries should be scoped and specific (avoid generic queries like just \"AI\" or \"LLM\").\n",
    "- If user asked for \"last week/this week/latest\", reflect that constraint IN THE QUERIES.\n",
    "\"\"\"\n",
    "\n",
    "def router_node(state: State) -> dict :\n",
    "    \n",
    "    topic = state['topic']\n",
    "\n",
    "    decider = llm.with_structured_output(RouterDecision)\n",
    "\n",
    "    decision = decider.invoke([\n",
    "        SystemMessage(content=ROUTER_SYSTEM),\n",
    "        HumanMessage(content=f\"Topic: {topic}\"),\n",
    "    ])\n",
    "\n",
    "    return {\n",
    "        \"needs_research\": decision.needs_research,\n",
    "        \"mode\": decision.mode,\n",
    "        \"queries\": decision.queries,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a46365ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_next(state: State) -> dict:\n",
    "\n",
    "    return \"research\" if state['needs_research'] else \"orchestrator\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a884b5a",
   "metadata": {},
   "source": [
    "## Research Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7f36e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tavily_search(query: str, max_results: int = 2) -> List[dict]:\n",
    "    \n",
    "    tool = TavilySearch(max_results=max_results)\n",
    "    response = tool.invoke({\"query\": query})\n",
    "\n",
    "    results = response.get(\"results\", []) if isinstance(response, dict) else []\n",
    "\n",
    "    normalized: List[dict] = []\n",
    "    for r in results or []:\n",
    "\n",
    "        if not isinstance(r, dict):\n",
    "            continue\n",
    "        \n",
    "        normalized.append(\n",
    "            {\n",
    "                \"title\": r.get(\"title\") or \"\",\n",
    "                \"url\": r.get(\"url\") or \"\",\n",
    "                \"snippet\": r.get(\"content\") or r.get(\"snippet\") or \"\",\n",
    "                \"published_at\": r.get(\"published_date\") or r.get(\"published_at\"),\n",
    "                \"source\": r.get(\"source\"),\n",
    "            }\n",
    "        )\n",
    "    return normalized\n",
    "\n",
    "RESEARCH_SYSTEM = \"\"\"You are a research synthesizer for technical writing.\n",
    "\n",
    "Given raw web search results, produce a deduplicated list of EvidenceItem objects.\n",
    "\n",
    "Rules:\n",
    "- Only include items with a non-empty url.\n",
    "- Prefer relevant + authoritative sources (company blogs, docs, reputable outlets).\n",
    "- If a published date is explicitly present in the result payload, keep it as YYYY-MM-DD.\n",
    "  If missing or unclear, set published_at=null. Do NOT guess.\n",
    "- Keep snippets short.\n",
    "- Deduplicate by URL.\n",
    "\"\"\"\n",
    "\n",
    "def research_node(state: State) -> dict:\n",
    "\n",
    "    queries = (state.get('queries',[]) or [])\n",
    "    max_results = 2 # total search max_result * queries\n",
    "\n",
    "    raw_results: List[dict] = []\n",
    "\n",
    "    for q in queries:\n",
    "        raw_results.extend(_tavily_search(q,max_results=max_results))\n",
    "\n",
    "    if not raw_results:\n",
    "        return {\"evidence\": []}\n",
    "    \n",
    "    extractor = llm.with_structured_output(EvidencePack)\n",
    "    pack = extractor.invoke([\n",
    "        SystemMessage(content=RESEARCH_SYSTEM),\n",
    "        HumanMessage(content=f\"Raw Results:\\n{raw_results}\"),\n",
    "    ])\n",
    "\n",
    "\n",
    "    dedup = {}\n",
    "\n",
    "    for e in pack.evidence:\n",
    "        if e.url:\n",
    "            dedup[e.url] = e\n",
    "\n",
    "    return {'evidence': list(dedup.values())}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156c57fa",
   "metadata": {},
   "source": [
    "## Orchestrator Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2eefc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCH_SYSTEM = \"\"\"You are a senior technical writer and developer advocate.\n",
    "Your job is to produce a highly actionable outline for a technical blog post.\n",
    "\n",
    "Hard requirements:\n",
    "- Create 1 sections (tasks) suitable for the topic and audience.\n",
    "- Each task must include:\n",
    "  1) goal (1 sentence)\n",
    "  2) 2-3 bullets that are concrete, specific, and non-overlapping\n",
    "  3) target word count (40-50)\n",
    "\n",
    "Quality bar:\n",
    "- Assume the reader is a developer; use correct terminology.\n",
    "- Bullets must be actionable: build/compare/measure/verify/debug.\n",
    "- Ensure the overall plan includes at least 2 of these somewhere:\n",
    "  * minimal code sketch / MWE (set requires_code=True for that section)\n",
    "  * edge cases / failure modes\n",
    "  * performance/cost considerations\n",
    "  * security/privacy considerations (if relevant)\n",
    "  * debugging/observability tips\n",
    "\n",
    "Grounding rules:\n",
    "- Mode closed_book: keep it evergreen; do not depend on evidence.\n",
    "- Mode hybrid:\n",
    "  - Use evidence for up-to-date examples (models/tools/releases) in bullets.\n",
    "  - Mark sections using fresh info as requires_research=True and requires_citations=True.\n",
    "- Mode open_book:\n",
    "  - Set blog_kind = \"news_roundup\".\n",
    "  - Every section is about summarizing events + implications.\n",
    "  - DO NOT include tutorial/how-to sections unless user explicitly asked for that.\n",
    "  - If evidence is empty or insufficient, create a plan that transparently says \"insufficient sources\"\n",
    "    and includes only what can be supported.\n",
    "\n",
    "Output must strictly match the Plan schema.\n",
    "\"\"\"\n",
    "\n",
    "def orchestrator_node(state: State)->dict :\n",
    "\n",
    "    planner = llm.with_structured_output(Plan)\n",
    "\n",
    "    evidence = state.get('evidence',[])\n",
    "    mode = state.get(\"mode\",\"closed_book\")\n",
    "\n",
    "    plan = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content = ORCH_SYSTEM),\n",
    "            HumanMessage(\n",
    "                content = (\n",
    "                    f\"Topic: {state['topic']}\\n\"\n",
    "                    f\"Mode: {mode}\\n\\n\"\n",
    "                    f\"Evidence (ONLY use for fresh claims; may be empty):\\n\"\n",
    "                    f\"{[e.model_dump() for e in evidence][:16]}\"\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {'plan':plan}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578fa47",
   "metadata": {},
   "source": [
    "### Fanout Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "fa8f9a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fanout(state: State):\n",
    "    return [\n",
    "        Send(\n",
    "            \"worker\",\n",
    "            {\n",
    "                \"task\": task.model_dump(),\n",
    "                \"topic\": state[\"topic\"],\n",
    "                \"mode\": state[\"mode\"],\n",
    "                \"plan\": state[\"plan\"].model_dump(),\n",
    "                \"evidence\": [e.model_dump() for e in state.get(\"evidence\", [])],\n",
    "            },\n",
    "        )\n",
    "        for task in state[\"plan\"].tasks\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a6ef18",
   "metadata": {},
   "source": [
    "## Worker Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3402f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKER_SYSTEM = \"\"\"You are a senior technical writer and developer advocate.\n",
    "Write ONE section of a technical blog post in Markdown.\n",
    "\n",
    "Hard constraints:\n",
    "- Follow the provided Goal and cover ALL Bullets in order (do not skip or merge bullets).\n",
    "- Stay close to Target words (Â±15%).\n",
    "- Output ONLY the section content in Markdown (no blog title H1, no extra commentary).\n",
    "- Start with a '## <Section Title>' heading.\n",
    "\n",
    "Scope guard:\n",
    "- If blog_kind == \"news_roundup\": do NOT turn this into a tutorial/how-to guide.\n",
    "  Do NOT teach web scraping, RSS, automation, or \"how to fetch news\" unless bullets explicitly ask for it.\n",
    "  Focus on summarizing events and implications.\n",
    "\n",
    "Grounding policy:\n",
    "- If mode == open_book:\n",
    "  - Do NOT introduce any specific event/company/model/funding/policy claim unless it is supported by provided Evidence URLs.\n",
    "  - For each event claim, attach a source as a Markdown link: ([Source](URL)).\n",
    "  - Only use URLs provided in Evidence. If not supported, write: \"Not found in provided sources.\"\n",
    "- If requires_citations == true:\n",
    "  - For outside-world claims, cite Evidence URLs the same way.\n",
    "- Evergreen reasoning is OK without citations unless requires_citations is true.\n",
    "\n",
    "Code:\n",
    "- If requires_code == true, include at least one minimal, correct code snippet relevant to the bullets.\n",
    "\n",
    "Style:\n",
    "- Short paragraphs, bullets where helpful, code fences for code.\n",
    "- Avoid fluff/marketing. Be precise and implementation-oriented.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def worker_node(payload: dict) -> dict:\n",
    "\n",
    "    task = Task(**payload[\"task\"])\n",
    "    plan = Plan(**payload['plan'])\n",
    "    evidence = [EvidenceItem(**e) for e in payload.get(\"evidence\",[])]\n",
    "    topic = payload['topic']\n",
    "    mode = payload.get(\"mode\",\"closed_book\")\n",
    "\n",
    "    bullets_text = \"\\n -\" + \"\\n -\".join(task.bullets)\n",
    "\n",
    "    evidence_text = \"\"\n",
    "    if evidence:\n",
    "        evidence_text = \"\\n\".join(\n",
    "            f\"- {e.title} | {e.url} | {e.published_at or 'date:unknown'}\".strip()\n",
    "            for e in evidence[:20]\n",
    "        )\n",
    "    \n",
    "    section_md = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(content=WORKER_SYSTEM),\n",
    "            HumanMessage(\n",
    "                content=(\n",
    "                    f\"Blog title: {plan.blog_title}\\n\"\n",
    "                    f\"Audience: {plan.audience}\\n\"\n",
    "                    f\"Tone: {plan.tone}\\n\"\n",
    "                    f\"Blog kind: {plan.blog_kind}\\n\"\n",
    "                    f\"Constraints: {plan.constraints}\\n\"\n",
    "                    f\"Topic: {topic}\\n\"\n",
    "                    f\"Mode: {mode}\\n\\n\"\n",
    "                    f\"Section title: {task.title}\\n\"\n",
    "                    f\"Goal: {task.goal}\\n\"\n",
    "                    f\"Target words: {task.target_words}\\n\"\n",
    "                    f\"Tags: {task.tags}\\n\"\n",
    "                    f\"requires_research: {task.requires_research}\\n\"\n",
    "                    f\"requires_citations: {task.requires_citations}\\n\"\n",
    "                    f\"requires_code: {task.requires_code}\\n\"\n",
    "                    f\"Bullets:{bullets_text}\\n\\n\"\n",
    "                    f\"Evidence (ONLY use these URLs when citing):\\n{evidence_text}\\n\"\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "    ).content.strip()\n",
    "\n",
    "    return {\"sections\": [(task.id,section_md)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ac1ca",
   "metadata": {},
   "source": [
    "# Add SubGraph for Image in Reducer Node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4bdfb7",
   "metadata": {},
   "source": [
    "### Merge Content Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c96b87ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_content(state: State) -> dict:\n",
    "\n",
    "    plan = state[\"plan\"]\n",
    "\n",
    "    ordered_sections = [md for _, md in sorted(state[\"sections\"], key=lambda x: x[0])]\n",
    "    body = \"\\n\\n\".join(ordered_sections).strip()\n",
    "    merged_md = f\"# {plan.blog_title}\\n\\n{body}\\n\"\n",
    "    return {\"merged_md\": merged_md}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f3c41",
   "metadata": {},
   "source": [
    "### Decide Image Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "94612e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DECIDE_IMAGES_SYSTEM = \"\"\"You are an expert technical editor.\n",
    "Decide if images/diagrams are needed for THIS blog.\n",
    "\n",
    "Rules:\n",
    "- Max 1 images total.\n",
    "- Each image must materially improve understanding (diagram/flow/table-like visual).\n",
    "- Insert placeholders exactly: [[IMAGE_1]], [[IMAGE_2]], [[IMAGE_3]].\n",
    "- If no images needed: md_with_placeholders must equal input and images=[].\n",
    "- Avoid decorative images; prefer technical diagrams with short labels.\n",
    "Return strictly GlobalImagePlan.\n",
    "\"\"\"\n",
    "\n",
    "def decide_images(state: State) -> dict:\n",
    "    \n",
    "    planner = llm.with_structured_output(GlobalImagePlan)\n",
    "    merged_md = state[\"merged_md\"]\n",
    "    plan = state[\"plan\"]\n",
    "    assert plan is not None\n",
    "\n",
    "    image_plan = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=DECIDE_IMAGES_SYSTEM),\n",
    "            HumanMessage(\n",
    "                content=(\n",
    "                    f\"Blog kind: {plan.blog_kind}\\n\"\n",
    "                    f\"Topic: {state['topic']}\\n\\n\"\n",
    "                    \"Insert placeholders + propose image prompts.\\n\\n\"\n",
    "                    f\"{merged_md}\"\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"md_with_placeholders\": image_plan.md_with_placeholders,\n",
    "        \"image_specs\": [img.model_dump() for img in image_plan.images],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f131c7f",
   "metadata": {},
   "source": [
    "### Generate and place Image node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "972139ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def _gemini_generate_image_bytes(prompt: str) -> bytes:\n",
    "    \"\"\"\n",
    "    Returns raw image bytes generated by Gemini.\n",
    "    Requires: pip install google-genai\n",
    "    Env var: GOOGLE_API_KEY\n",
    "    \"\"\"\n",
    "    from google import genai\n",
    "    from google.genai import types\n",
    "\n",
    "    api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"GOOGLE_API_KEY is not set.\")\n",
    "\n",
    "    client = genai.Client(api_key=api_key)\n",
    "\n",
    "    resp = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash-preview-image\",\n",
    "        contents=prompt,\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_modalities=[\"IMAGE\"],\n",
    "            safety_settings=[\n",
    "                types.SafetySetting(\n",
    "                    category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "                    threshold=\"BLOCK_ONLY_HIGH\",\n",
    "                )\n",
    "            ],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Depending on SDK version, parts may hang off resp.candidates[0].content.parts\n",
    "    parts = getattr(resp, \"parts\", None)\n",
    "    if not parts and getattr(resp, \"candidates\", None):\n",
    "        try:\n",
    "            parts = resp.candidates[0].content.parts\n",
    "        except Exception:\n",
    "            parts = None\n",
    "\n",
    "    if not parts:\n",
    "        raise RuntimeError(\"No image content returned (safety/quota/SDK change).\")\n",
    "\n",
    "    for part in parts:\n",
    "        inline = getattr(part, \"inline_data\", None)\n",
    "        if inline and getattr(inline, \"data\", None):\n",
    "            return inline.data\n",
    "\n",
    "    raise RuntimeError(\"No inline image bytes found in response.\")\n",
    "\n",
    "\n",
    "def generate_and_place_images(state: State) -> dict:\n",
    "\n",
    "    plan = state[\"plan\"]\n",
    "    assert plan is not None\n",
    "\n",
    "    md = state.get(\"md_with_placeholders\") or state[\"merged_md\"]\n",
    "    image_specs = state.get(\"image_specs\", []) or []\n",
    "\n",
    "    # If no images requested, just write merged markdown\n",
    "    if not image_specs:\n",
    "        filename = f\"{plan.blog_title}.md\"\n",
    "        Path(filename).write_text(md, encoding=\"utf-8\")\n",
    "        return {\"final\": md}\n",
    "\n",
    "    images_dir = Path(\"images\")\n",
    "    images_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for spec in image_specs:\n",
    "        placeholder = spec[\"placeholder\"]\n",
    "        filename = spec[\"filename\"]\n",
    "        out_path = images_dir / filename\n",
    "\n",
    "        # generate only if needed\n",
    "        if not out_path.exists():\n",
    "            try:\n",
    "                img_bytes = _gemini_generate_image_bytes(spec[\"prompt\"])\n",
    "                out_path.write_bytes(img_bytes)\n",
    "            except Exception as e:\n",
    "                # graceful fallback: keep doc usable\n",
    "                prompt_block = (\n",
    "                    f\"> **[IMAGE GENERATION FAILED]** {spec.get('caption','')}\\n>\\n\"\n",
    "                    f\"> **Alt:** {spec.get('alt','')}\\n>\\n\"\n",
    "                    f\"> **Prompt:** {spec.get('prompt','')}\\n>\\n\"\n",
    "                    f\"> **Error:** {e}\\n\"\n",
    "                )\n",
    "                md = md.replace(placeholder, prompt_block)\n",
    "                continue\n",
    "\n",
    "        img_md = f\"![{spec['alt']}](images/{filename})\\n*{spec['caption']}*\"\n",
    "        md = md.replace(placeholder, img_md)\n",
    "\n",
    "    filename = f\"{plan.blog_title}.md\"\n",
    "    Path(filename).write_text(md, encoding=\"utf-8\")\n",
    "    return {\"final\": md}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b33b35",
   "metadata": {},
   "source": [
    "## Reducer SubGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b36966b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001336B214590>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reducer_graph = StateGraph(State)\n",
    "\n",
    "reducer_graph.add_node('merge_content',merge_content)\n",
    "reducer_graph.add_node('decide_images',decide_images)\n",
    "reducer_graph.add_node('generate_and_place_images',generate_and_place_images)\n",
    "\n",
    "reducer_graph.add_edge(START,\"merge_content\")\n",
    "reducer_graph.add_edge('merge_content','decide_images')\n",
    "reducer_graph.add_edge('decide_images','generate_and_place_images')\n",
    "reducer_graph.add_edge('generate_and_place_images',END)\n",
    "\n",
    "reducer_subgraph = reducer_graph.compile()\n",
    "\n",
    "reducer_subgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4231237",
   "metadata": {},
   "source": [
    "# Graph Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "526eedde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1336b5b4b90>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = StateGraph(State)\n",
    "G.add_node(\"router\",router_node)\n",
    "G.add_node(\"research\",research_node)\n",
    "G.add_node(\"orchestrator\",orchestrator_node)\n",
    "G.add_node(\"worker\",worker_node)\n",
    "G.add_node(\"reducer\",reducer_subgraph)\n",
    "\n",
    "G.add_edge(START,'router')\n",
    "G.add_conditional_edges(\"router\",route_next,{\"research\":\"research\",\"orchestrator\":'orchestrator'})\n",
    "G.add_edge(\"research\",\"orchestrator\")\n",
    "\n",
    "G.add_conditional_edges(\"orchestrator\",fanout,['worker'])\n",
    "G.add_edge(\"worker\",\"reducer\")\n",
    "G.add_edge(\"reducer\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "119a931a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001336B5B7B10>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = G.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "89564fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(topic: str):\n",
    "    out = app.invoke(\n",
    "        {\n",
    "            \"topic\": topic,\n",
    "            \"mode\": \"\",\n",
    "            \"needs_research\": False,\n",
    "            \"queries\": [],\n",
    "            \"evidence\": [],\n",
    "            \"plan\": None,\n",
    "            \"sections\": [],\n",
    "            \"final\": \"\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "af741473",
   "metadata": {},
   "outputs": [
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 49.154544343s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '49s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3047\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3046\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3049\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\google\\genai\\models.py:5474\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5473\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5474\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5475\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5476\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5478\u001b[39m function_map = _extra_utils.get_function_map(parsed_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\google\\genai\\models.py:4214\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   4212\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m4214\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4215\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   4216\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4219\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4220\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1396\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1393\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1394\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1395\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1397\u001b[39m response_body = (\n\u001b[32m   1398\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1399\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1230\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1229\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:470\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:371\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:413\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:184\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:473\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1209\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1202\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1203\u001b[39m     method=http_request.method,\n\u001b[32m   1204\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1207\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1208\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1211\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1212\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:134\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    132\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:159\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 49.154544343s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '49s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[246]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mChatgpt History\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[245]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(topic)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(topic: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     out = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtopic\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmode\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mneeds_research\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mqueries\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mevidence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mplan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msections\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfinal\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3071\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3068\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3069\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3071\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[233]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mrouter_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     22\u001b[39m topic = state[\u001b[33m'\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     24\u001b[39m decider = llm.with_structured_output(RouterDecision)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m decision = \u001b[43mdecider\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mROUTER_SYSTEM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTopic: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtopic\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mneeds_research\u001b[39m\u001b[33m\"\u001b[39m: decision.needs_research,\n\u001b[32m     33\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m: decision.mode,\n\u001b[32m     34\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mqueries\u001b[39m\u001b[33m\"\u001b[39m: decision.queries,\n\u001b[32m     35\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3155\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3153\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3155\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3156\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3157\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5695\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5688\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5689\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5690\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5693\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5694\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5695\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5696\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5697\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5698\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5699\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2535\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2532\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2533\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:402\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1121\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m     **kwargs: Any,\n\u001b[32m   1119\u001b[39m ) -> LLMResult:\n\u001b[32m   1120\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:931\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    930\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m         )\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    939\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1233\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1231\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1237\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3051\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3047\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28mself\u001b[39m.client.models.generate_content(\n\u001b[32m   3048\u001b[39m         **request,\n\u001b[32m   3049\u001b[39m     )\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m3051\u001b[39m     \u001b[43m_handle_client_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3053\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Machine Learning and Data Science\\Autonomous-Content-Engine\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:145\u001b[39m, in \u001b[36m_handle_client_error\u001b[39m\u001b[34m(e, request)\u001b[39m\n\u001b[32m    143\u001b[39m model_name = request.get(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    144\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calling model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 49.154544343s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '49s'}]}}",
      "During task with name 'router' and id 'f16dbaa5-decd-b1f6-6773-38166c45f773'"
     ]
    }
   ],
   "source": [
    "run(\"Chatgpt History\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0dd81e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autonomous-content-engine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
